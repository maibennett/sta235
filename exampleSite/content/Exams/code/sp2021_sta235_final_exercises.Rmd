---
title: "Final Exam - Review Excercises"
author: "STA 235"
date: "05/05/2021"
output: 
  html_document:
    css: style.css 
    toc: no
  pdf_document: 
    css: style.css
    toc: no
---


# I want to ride my bicycle... 

We are going to use the example we saw in class, and play around with this dataset to answer two main questions:

1. How can we predict daily demand? (in the short term)
2. How can we incentivize the use of bike share?


## Prediction

We will be using data from DC. This is the data we have:

```{r, warning = FALSE, message = FALSE}
library(tidyverse)
library(ggplot2)

bikedc <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Classes/Week14/2_Wrapup/data/bikesharedc.csv")

bikedc <- bikedc %>% mutate(season = factor(season),
                            weather = factor(weather),
                            date = as.Date(datetime))

head(bikedc)
```

1) Complete the following code to transform the data to make it daily (instead of hour/day). You need to change the "XXXX" to make it an appropriate line to run. 
*Note: Use an average for continuous variables and the mode for factor variables. We also add all uses for the outcome*.

```{r, warning = FALSE, message = FALSE, eval = FALSE}
# Function thatreturns the mode of a vector
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

bikedc_daily <- "XXXX" %>% select(-datetime) %>% group_by("XXXX") %>%
  summarise(across(where(is.numeric) & !c(casual, registered, count), ~mean(.x, na.rm = TRUE), .names = "m_{.col}"),
    across(where("XXXX"), ~getmode(.x), .names = "m_{.col}"),
    across(c(casual, registered, count), ~sum(.x), .names = "total_{.col}"))


rm(bikedc) # We will remove the bikedc dataframe from the session to free up some memory, if needed.
```


2) Select 50% of the sample for training and 50% for testing, Estimate your prediction RMSE using an **OLS model** using all the covariates. What is your outcome variable? Are there any variable you should leave out in your data set and why/why not? Show your RMSE.


3) Do you think the previous model is a good prediction model or not? Talk about the advantages and disadvantages both in terms of bias and variance.


4) Using the same training/testing dataset, now use a Lasso regularization for the previous model. 

- In your own words, why could Lasso help in this case? 
- Plot the regularization parameter vs the RMSE and interpret the plot using your own words. 
- What is the optimal shrinkage parameter? 

*Note: Only use 5 cross-validation folds and use the `lambda_seq` vector provided*

```{r}
lambda_seq <- c(0,10^seq(-3, 3, length = 200))

```


5) Using the previous results, show the model that lasso selected for prediction. How does it compare to the previous OLS model? Use the lasso model for prediction and estimate the RMSE. How does it compare to your previous OLS results?


6) What would the advantages be of using a KNN approach compared to the OLS model we first fitted?


7) Use bagging in combination with decision trees to get a final estimate of RMSE. 

- What covariates are the most important? Which ones are the least important?

- Show your estimate of the RMSE.

- Why do you think the model that did better (according to your results) had better predictions than the others?

*Note: Only use 5 cross-validation folds and 15 bagged trees*


8) Do you think Random Forests would do better? Why? How would it compare to the previous bagging algorithm in terms of variance and bias?



## Causal Inference

Now assume we want to estimate the effect of certain interventions to incentivize the use of bike shares

1) Imagine that the intervention you had in mind was to reduce the price for causal riders and increase the price for registered riders. You are present in multiple cities in the US and you randomize this interventions at the city level. 

- What would your outcome(s) of interest be?

- What would your estimand(s) of interest be? Explain it in terms of potential outcomes.


2) What would be a check that you would run to ensure that randomization was done correctly?

3) Could there be a problem with non-compliance here? Why or why not?

---

Unfortunately, we did not get the approval to run an RCT, but we know that NYC experienced a similar change to the one we want to test in 2012.

4) What identification strategy would you use for this? Why do you think it would identify a causal estimate? What assumptions need to hold? Why could those assumptions fail? Give examples.


5) Here is the daily data for bike share in NYC, under the same structure as `bikedc_daily`. Create a new variable called `nyc` for each dataframe (which should be 1 for NYC and 0 for DC), and append both datasets

*Note: you can extract the year of a date by using as.numeric(format(date, format="%Y"))*


```{r, warning = FALSE, message = FALSE}
bikenyc_daily <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Classes/Week14/2_Wrapup/data/bikesharenyc_daily.csv")

bikenyc_daily <- bikenyc_daily %>% mutate(date = as.Date(date),
                                          m_season = factor(m_season),
                                          m_weather = factor(m_weather))

```


6) Compare the (numeric) **weather covariates** for NYC and DC in 2011. Are these covariate balanced? Does this pose a problem for causal identification? Explain.


7) Now you want to fit a differences-in-differences model for `total_count`, `total_casual`, and `total_registered`. What are the two-dimensions for DD here? Create any variable you might need, fit the model and explain your results. What conclusion can you make from these results?


8) Make a plot for date and `total_count` for NYC and DC (in the same plot, different colors). Use `geom_smooth(method = "gam")` to help you out. Do you think that the parallel trend assumption holds? why or why not? Explain.


9) One of your co-workers comes with an analysis comparing New York data before and after, saying that the change was tremendously successful (run the code below). How would you respond to this? Use DC data to support your argument.

```{r, echo=TRUE, eval=FALSE}
summary(lm(total_count ~ y2012, data = bike_daily %>% filter(nyc==1)))
```

10) Another co-worker laughs at the first one, saying that before-and-after is a ridiculous comparison, and that the real comparison that we should run for estimating the effect of the change is compare NYC and DC in the 2012. How would you respond to this? Use DC data to support your argument.

```{r, echo=TRUE, eval=FALSE}
summary(lm(total_count ~ nyc, data = bike_daily %>% filter(year==2012)))
```
