---
title: "Homework 2: Causal Inference - RCTs and Selection Bias"
author: "STA 235"
date: "Due on March 1st, 12:00pm"
output: 
  html_document:
    css: style.css 
    toc: no
  pdf_document: 
    css: style.css
    toc: no
---

<style type="text/css">
.main-container {
  max-width: 1800px;
  margin-left: auto;
  margin-right: auto;
}

@media only screen and (max-width: 700px) {
   body {
      margin: 0;
      padding: 0;
   }
   .sample {
      width: 100%;
   }
}
</style>

# Task 1: The fundamental causal problem

You are working for a company that has a member's reward program, and you want to know whether the program is effective or not. You have some 2019 data from this program, which was introduced in January 2019:

```{r setup, warning=FALSE, message=FALSE}

d <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Assignments/Homework2/data/rewards.csv")
```

The dataset has the following variables:

- `user_id`: unique id for the user.
- `signup_month`: Month (in 2019) the user signed up for the program. If =0, it means the user did not sign up.
- `month`: Month of the year.
- `spend`: Amount spent on the company's website.

Notice that the data has a panel structure, which means that each row is a user-month. Also, as a note, the rewards program doesn't kick off until the month after the user subscribes.

### Question 1.1:
**What is the treatment in this case? Write down the causal estimand you want to estimate as a function of the potential outcomes**.

*Answer: The treatment would be signing up the rewards program. So if Z=1 is participating in the rewards program, and Z=0 is not participating, then I can write the ATE as following*
$$ATE = E[Y_i(1) - Y_i(0)]$$
*where $Y_i$ is the amount of money the user spends on the website. So the average treatment effect would be the expected difference in the amount spent by a user if they participate in the program and the amount spent by a user if they didn't participate in the rewards program.*

### Question 1.2: 
**Create the variable `treatment` for each observation.**

*Answer: I create a variable treat as following*
```{r, , warning=FALSE, message=FALSE}
d$treat <- as.numeric(d$month>d$signup_month)
d$treat[d$signup_month==0] <- 0
```

### Question 1.3:
**Show a scatter plot spending by month, coloring observations that are in the treatment group *that month* in different colors. What can you say about the spending patterns between those users that sign up for the rewards program compared to those that do no?**. *Tip: To avoid two categories overlapping each other, you can use the `position = position_dodge(width=0.3)` argument in your scatter plot!*


*Answer: We can see that overall spending decreases over time, but the treatment group always have higher spending than the control group.*
```{r, , warning=FALSE, message=FALSE}
library(ggplot2)

ggplot(d, aes(x = factor(month), y = spend, color = factor(treat), fill = factor(treat))) +
  geom_point(size = 3, pch = 21, alpha = 0.4, position=position_dodge(width=0.3)) +
  theme_bw() + xlab("Month") + ylab("Spending")
```


Now, we are going to slice our data!

### Question 1.4:
**Create two new datasets: One with only the months of January and February (name it `d1`), and the second one with only the months of November and December (name it `d2`). Then, we will use `pivot_wider()` on each of the new dataframes to transform our data and obtain new dataframes with only ONE observation per user.**

*Tip: `pivot_wider()` is a function from the `tidyverse` package that transforms data from long format to wide format. See the following vignette for an example:*


![](https://github.com/maibennett/sta235/raw/main/exampleSite/content/Assignments/Homework2/images/pivot_wider.png)


*Answer: *
```{r, echo=TRUE, message=FALSE}
library(tidyverse)

d1 <- d %>% filter(month==1 | month==2)

d2 <- d %>% filter(month==11 | month==12)


d1 <- d1 %>% pivot_wider(id_cols = user_id, names_from = month, values_from = c(spend, treat))

d2 <- d2 %>% pivot_wider(id_cols = user_id, names_from = month, values_from = c(spend, treat))

```
 
### Question 1.5:
**Using the previous datasets that you created (`d1` and `d2`, after using `pivot_wider()`), fit an appropriate model to estimate the estimand in 1.1. What variables would you use as controls? Would you exclude any observations in one of the analysis? Justify your choices and assumptions for making causal inference.**

*Answer: For `d1`, the model I would fit spending in the post intervention period on being treated on that period and using baseline spending as the covariate*

```{r, echo=TRUE, message=FALSE}
summary(lm(spend_2 ~ treat_2 + spend_1, data = d1))
```
*Under the ignorability assumption, the effect of subscribing to the rewards program on website spending is of $99.6 for the month of February.*

*For the second model, using `d2`, we will only focus on those users that had not signed up for the rewards program in November, and then run the same model as before:*

```{r, echo=TRUE, message=FALSE}
d2_filter <- d2 %>% filter(treat_11==0) 

summary(lm(spend_12 ~ treat_12 + spend_11, data = d2_filter))
```
*Under the ignorability assumption, the effect of subscribing to the rewards program on website spending is of $101.4 for the month of February.*

### Question 1.4:
**Identify at least one potential problem with the causal interpretation of the previous estimates. Be specific!**

*Answer: One of the main problems with causal interpretation in this case, is that the ignorability assumption might not hold. For example, users that already intended to buy more from the website were more likely to sign up for the rewards. In that sense, the expectation of future spending might have confounded the causal effect.*

---

# Task 2: Two samples, one way

## The Setup

The [National Supported Work Demonstration (NSW)](https://www.jstor.org/stable/1806062?seq=1#metadata_info_tab_contents) was a small program targeted at disadvantaged low-wage workers in 1976. This program was ran as an experiment, which means that after workers applied to it, they were randomized either into the treatment group (training program) or the control group. The data for this small RCT is given in the dataset `sample_rct`:

```{r setup2a, warning=FALSE, message=FALSE}
sample_rct <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Assignments/Homework2/data/nsw_dehejia_wahba_ps.csv")

```

Additionally, we also have data from the [Panel Study of Income Dynamics](https://amstat.tandfonline.com/doi/abs/10.1080/01621459.1999.10473858?casa_token=iOA-bIxeJFwAAAAA:X1Ugphi2-YBRwAnmkGERackdyJYQrpDmD2RZnvG4nngJdwqi1NGOPj-BB0gjmcMEc3v2lNROJAN1#.YBWz2OhKguU) in the dataset `sample_all`. In this case, these respondents did not participate in the NSW program, but we can assume they are a representative sample of workers from the same year in the US.

```{r setup2b, warning=FALSE, message=FALSE}
sample_all <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Assignments/Homework2/data/nsw_dehejia_wahba_psid.csv")

```

For both samples, the variables are the following:

- `data_id`: Where the data comes from.
- `treat`: Whether the person participated in the training program or not.
- `age`: Age (in years).
- `education`: Years of education.
- `black`: Whether the person is African-american (1) or not (0).
- `hispanic`: Whether the person is Hispanic (1) or not (0).
- `married`: Whether the person is married (1) or not (0).
- `nodegree`: Whether the person did not finish high school (1) or not (0).
- `re7x`: Earnings in the year 197x.

---

## The Effect of a Training Program

First, you want to check whether the randomization was done correctly in the RCT sample:

### Question 2.1:
**Compare the covariates between the treatment and control group in your `sample_rct` data. What conclusions can you make?** *Note: Remember to only show covariate balance! We are not looking at the outcome yet.*

*Answer: We can see that overall, the data is well balanced. The two variables that are not balanced between groups are no degree (difference is significant at 1% level), and hispanic, which is significant at the 10% level. These differences can be attributed to chance.*

```{r, echo=TRUE, message=FALSE}
library(designmatch)

covs <- sample_rct %>% dplyr::select(-c(data_id,treat,re78))

meantab(covs, sample_rct$treat, which(sample_rct$treat==1), which(sample_rct$treat==0))
```

### Question 2.2:
**Using the experimental sample, estimate the effect of the NSW program. Run models both with and without covariates. How do the estimates change and why?**

*Answer: The coefficient for treatment shows a slight decrease, most likely because of random unbalances between both groups. Still, the magnitude of the coefficient doesn't present substantial changes. With the inclusion of other covariates, however, we do get narrower confidence intervals for our estimate of the treatment effect.*
```{r, echo=TRUE, message=FALSE}
library(modelsummary)

lm1 <- lm(re78 ~ treat, d = sample_rct)
lm2 <- lm(re78 ~ treat + age + education + black + hispanic + married + nodegree + re74 + re75, d = sample_rct)

modelsummary(list(lm1,lm2), stars = TRUE)
```


These results are great, but you actually want to estimate the effect of this training program on the entire working population. 

### Question 2.3:
**Create a table or plot comparing some key the characteristics of both samples, particularly focusing on the control groups. What differences can you observe?**

*Answer: We can see that there are many differences between the control group in the RCT in the population.*

```{r, echo=TRUE, message=FALSE}
control_rct <- sample_rct %>% filter(treat==0) %>% mutate(rct = 1)

sample_all_append <- sample_all %>% mutate(rct = 0) %>% add_row(control_rct)

covs_all_append <- sample_all_append %>% dplyr::select(-c(data_id,treat,re78, rct))
# Control is going to be the population sample and treatment is going to be the control group from the treatment sample

meantab(covs_all_append, sample_all_append$rct, which(sample_all_append$rct==1),which(sample_all_append$rct==0))

```


### Question 2.4:
**If you only had the experimental sample, what would be the drawbacks of your estimate? Is there something you could do about it?**

*Answer: The problem is that the estimate, even though is causal, will not be representative of the general population (i.e. no external validity).*

### Question 2.6:
**Create a new data set with both the treatment group in `sample_rct` and also `sample_all`, match units in the treatment group with units in the control group both using nearest neighbor and optimal, and describe your matched sample. How does it compare to the balance of the original RCT sample?**

*Answer: We can see that both methods find the same number of matches, and both don't do a great job balancing both groups (we haven't used calipers in this case). Optmatch seems to match certain variables worse than NN, but does better in other cases (e.g. nodegree). Overall, still optmatch should do at least as good of a job as nearest neighbor in terms of overall matching due to the optimization process.*

```{r, echo=TRUE, message=FALSE}
treatment_rct <- sample_rct %>% filter(treat==1)

sample_all_append <- sample_all %>% add_row(treatment_rct)

library(MatchIt)

m.nn <- matchit(treat ~ age + education + black + hispanic + married + nodegree + re74 + re75, data = sample_all_append, method="nearest")
m.opt <- matchit(treat ~ age + education + black + hispanic + married + nodegree + re74 + re75, data = sample_all_append, method="optimal")

length(m.nn$match.matrix)
length(m.opt$match.matrix)

summary(m.nn)
summary(m.opt)

## NN
t_id_nn <- as.numeric(rownames(m.nn$match.matrix))
c_id_nn <- as.numeric(m.nn$match.matrix[,1])

matched_nn <- sample_all_append[c(t_id_nn,c_id_nn),]

library(designmatch)

matched_nn_covs <- matched_nn %>% dplyr::select(age, education, black, hispanic, married, nodegree, re74, re75)

meantab(matched_nn_covs, matched_nn$treat, which(matched_nn$treat==1),which(matched_nn$treat==0))

## optmatch
t_id_opt <- as.numeric(rownames(m.opt$match.matrix))
c_id_opt <- as.numeric(m.opt$match.matrix[,1])

matched_opt <- sample_all_append[c(t_id_opt,c_id_opt),]

matched_opt_covs <- matched_opt %>% dplyr::select(age, education, black, hispanic, married, nodegree, re74, re75)

meantab(matched_opt_covs, matched_opt$treat, which(matched_opt$treat==1),which(matched_opt$treat==0))

```

### Question 2.7:
**Compare the results of the matched sample (using optmatch) to those of the experimental sample, both using and not using covariates. Can you replicate an experimental result with this observational data? Why or why not?**

*Answer: There are important changes because the samples are not very well balanced, even after doing optmatch (we should have set a caliper for better matches)*
```{r, echo=TRUE, message=FALSE, warning = FALSE}
control_id_all <- as.numeric(m.opt$match.matrix)
treat_id_all <- as.numeric(rownames(m.opt$match.matrix))

sample_all_append <- sample_all_append[c(control_id_all,treat_id_all),]

lm3 <- lm(re78 ~ treat, d = sample_all_append)
lm4 <- lm(re78 ~ treat + age + education + black + hispanic + married + nodegree + re74 + re75, d = sample_all_append)

modelsummary(list(lm3,lm4), stars = TRUE)
```


### Question 2.8:
**Use IPW to estimate an ATE, using weights to approximate the general population in your RCT sample**

*Answer: We want our RCT sample to look like our general sample, so in this case, because we will append both dataframes, we will use the ATT formula for weights.*

```{r, echo = TRUE, warning = FALSE}
# Generate a whole sample:
sample_rct <- sample_rct %>% mutate(general = 0)

sample_all_append <- sample_all %>% mutate(general = 1) %>% add_row(sample_rct)

# Estimate the propensity scores

m1 <- glm(general ~ age + education + black + hispanic + married + nodegree + re74 + re75,
          data = sample_all_append,
          family = binomial(link = "logit"))

library(generics)

sample_rct_weights <- augment(m1, newdata = sample_rct, type.predict ="response")

sample_rct_weights <- sample_rct_weights %>% mutate(ipw = .fitted*general/.fitted + (.fitted*(1-general)/(1-.fitted))) 

lm1_ipw <- lm(re78 ~ treat, data = sample_rct_weights, weights = ipw)

modelsummary(list(lm1, lm1_ipw), stars = TRUE)
```

### Question 2.9:
**Do you think the previous effect (using IPW) would be the ATE if the government decided to scale-up the program? Why or why not?**

*Answer: Probably not because of general equilibrium effects. In this case, training everyone who is unemployed would most likely create congestion problems.*

---

# Task 3: Breaking the assumptions

## Pilot away!

You are doing an internship at an ed tech firm, and they know you've taken this course. Knowing that you have expertise in Causal Inference, your boss asks you to run a small pilot to test different recommendation algorithms for their phone application, which is targeted at students. The main goal is to increase the number of app installs. You start with a small sample of McCombs students (from different departments) to pilot your strategy, and randomize students into algorithm A or B. Here is the data for your pilot:

```{r setup3, warning=FALSE, message=FALSE}

pilot_mc <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Assignments/Homework2/data/user_app_installed_mccombs_small.csv")

```
Where you have the following variables:

- `female`: Student is female
- `graduate`: Graduate student
- `freshmen`: Freshmen
- `Activity`: Phone activity from 1 (Low) to 4 (High)
- `algorithm`: Whether the student was randomized into algorithm A or B.
- `installed`: Whether the student installed the app or not.


### Question 3.1
**What is your treatment? What is your control group?**

*Answer: We will assume the treatment is algorithm B and the control is algorithm A. Note: It doesn't really matter as long as we are consistent.*

### Question 3.2
**Given your previous answer, can you write the causal questions for this setting? What would the counterfactual be?**

*Answer: The causal question what is the effect on number of app installations for algorithm B compared to algorithm A? In this case, the counterfactual would be the number of app installations if we used the recommendation algorithm B instead of A on the same sample.*

---

Now, you want to assess the effect of your treatment.

### Question 3.3
**Write down the model and estimate the necessary parameters. If you include covariates, remember to justify your choices!**

*Answer: We first check balance, and then run a simple regression. We include covariates later to see if the point estimate changes. It does decrease a little bit, and so does the SE (because we included covariates). Note: Not necessary to show balance first, but it helps to justify why they would include covariates or not.*
```{r, warning=FALSE, message=FALSE}
meantab(pilot_mc[,-c(5,6)],pilot_mc$algorithm=="B",which(pilot_mc$algorithm=="B"), which(pilot_mc$algorithm=="A"))

library(estimatr)

# First we run the simple regression (because we randomized the treatment)
summary(estimatr::lm_robust(installed ~ factor(algorithm), data = pilot_mc))

# We add covariates just to improve precision
summary(estimatr::lm_robust(installed ~ factor(algorithm) + female + graduate + freshmen + activity, data = pilot_mc))

```
---

## Expanding your sample

Your boss is encouraged about your preliminary results, and now asks you to run the same experiment on a bigger sample. You'll now have to randomize a much larger sample of students at McCombs! Here are those results:

```{r setup4, warning=FALSE, message=FALSE}

full_mc <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Assignments/Homework2/data/user_app_installed_mccombs_large.csv")

```

### Question 3.4
**Estimate the treatment effect on the new sample. How did it change compared to your pilot? Why do you think this is?**

*Answer: The estimate in this second model is much smaller in magnitude, most likely because of spillovers. People in different groups might be talking to each other about the app, so SUTVA doesn't hold.*

```{r, warning=FALSE, message=FALSE}
summary(estimatr::lm_robust(installed ~ factor(algorithm), data = full_mc))

```

### Question 3.5
**Show (in a plot or a table) the outcome for both treatment and control groups by sample (original pilot sample and the expanded sample). What differences do you see? Is this a problem for causal identification?**

*Answer: Given that the characteristics don't look that different between the two samples, we can assume that maybe there was some interference. Given that a large portion of McCombs got treated, this could have affected people in the control group if they shared information', thus diluting the effect.*
```{r, warning=FALSE, message=FALSE}
d_total <- pilot_mc %>% mutate(pilot = 1) %>%
  add_row(full_mc)

d_total$pilot[is.na(d_total$pilot)] <- 0

table(d_total$pilot, d_total$installed)

meantab(d_total[,-c(5,6,7)], d_total$pilot, which(d_total$pilot==1),which(d_total$pilot==0))
```

---

## Let's go global (UT global)

To avoid interference and gain more statistical power, you decide to use the same sample size as before, but now stratify by small. This means that you will only choose a small number of students from different academic units. Here's your final data:

```{r setup5, warning=FALSE, message=FALSE}

data_ut <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Assignments/Homework2/data/user_app_installed_UT_large.csv")

```

### Question 3.6
**Estimate the treatment effect on this new stratified sample. How did it change compared to your pilot?**

*Answer: The effect is slightly smaller (in magnitude), most likely because we are estimating an effect for different populations.*
```{r, warning=FALSE, message=FALSE}
summary(estimatr::lm_robust(installed ~ factor(algorithm) + factor(unit), data = data_ut))
```

### Question 3.7
**Assuming interference is not a problem here, why are results different from the previous models? Justify your answer and make appropriate plots/tables to sustain your argument.**

*Answer: Because we are calculating these results for a different population (McCombs students are not necessarily the same as all UT students), and if treatment is different based on certain characteristics, we should expect a different estimate. We can compare the characteristics between both samples (pilot and full UT, for example), and clearly see that students at McCombs have a higher level of activity than those at UT in general, which could be driving some of these differences.*

```{r,warning=FALSE, message=FALSE}
d_total2 <- pilot_mc %>% mutate(pilot = 1,
                                unit = NA) %>%
  add_row(data_ut)

d_total2$pilot[is.na(d_total2$pilot)] <- 0

d_total2_covs <- d_total2 %>% dplyr::select(female, graduate, freshmen, activity)

meantab(d_total2_covs, d_total2$pilot, which(d_total2$pilot==1), which(d_total2$pilot==0))
```

<!-- pagedown::chrome_print('C:/Users/mc72574/Dropbox/UT/Teaching/Assignments/Homework2/STA235_Homework2_AnswerKey.html') -->
