model3 <- estimatr::lm_robust(deny ~ pirat + factor(afam), data = hmda)
summary(model3)
## Logistic Regression
logit1 <- glm(deny ~ pirat, family = binomial(link = "logit"),
data = hmda)
prob <- predict(logit1, type = "response") # probabilities
# Let's plot the predicted probabilities using logit and the data that we have!
ggplot(data = hmda, aes(x = pirat, y = deny)) +
geom_point(color = "#5601A4", fill = alpha("#5601A4",0.4), pch=21, size = 3)+ # This is a scatter plot for the data
geom_line(aes(x = hmda$pirat, y = prob), color = "#BF3984", se = FALSE, lty = 1, lwd = 1.3) + #This are the fitted probabilities
geom_hline(aes(yintercept = 0), color="dark grey", lty = 2, lwd=1)+
geom_hline(aes(yintercept = 1), color="dark grey", lty = 2, lwd=1)+
theme_bw()+
xlab("Payment/Income ratio") + ylab("Deny")
# To interpret coefficients, we need to choose the values for the other variables (in this case,
# the mean for payments to income ratio)
logit2 <- glm(deny ~ pirat + factor(afam), family = binomial(link = "logit"),
data = hmda) # This is the model we are fitting with two covariates
# We need to pass to predict: The model we fitted, the new data we want to fit our probabilities (if we leave blank, it uses the original hmda data)
# and we need to say type = "response" to get *probabilities* (and not odds, or log odds, or anything else)
predictions_afam <- predict(logit2, newdata = data.frame("afam" = c("no", "yes"),
"pirat" = c(mean(hmda$pirat), mean(hmda$pirat))),
type = "response")
# These are the predictions for two observations with the same payment/income ratio (the mean of our data)
# and where one is african american and the other one is not.
predictions_afam
# Difference between both predictions
diff(predictions_afam)
# Let's plot the predicted probabilities using logit and the data that we have!
ggplot(data = hmda, aes(x = pirat, y = deny)) +
geom_point(color = "#5601A4", fill = alpha("#5601A4",0.4), pch=21, size = 3)+ # This is a scatter plot for the data
geom_line(aes(x = pirat, y = prob), color = "#BF3984", se = FALSE, lty = 1, lwd = 1.3) + #This are the fitted probabilities
geom_hline(aes(yintercept = 0), color="dark grey", lty = 2, lwd=1)+
geom_hline(aes(yintercept = 1), color="dark grey", lty = 2, lwd=1)+
theme_bw()+
xlab("Payment/Income ratio") + ylab("Deny")
##############################################################
### Title: "Week 2 - Multiple Regression and Binary Outcomes"
### Course: STA 235
### Semester: Spring 2021
### Professor: Magdalena Bennett
##############################################################
# Clears memory
rm(list = ls())
# Clears console
cat("\014")
### Load libraries
# If you don't have one of these packages installed already, you will need to run install.packages() line
library(tidyverse)
library(ggplot2)
library(generics)
library(ggcorrplot)
################################################################################
### Statistical adjustment
################################################################################
# Read weekly sales data:
# p1: price for product 1
# p2: price for product 2
# Sales: sales for product 1 (compared to a baseline)
sales <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Classes/Week2/1_OLS/data/PricesSales.csv")
#Look at some of the data
head(sales)
# Let's run a linear model
# - Use lm() to run a linear model
# - The function `summary()` provides additional information (like SE and R2)
summary(lm(Sales ~ p1 + p2, data = sales))
# Obtain fitted values and residuals (you can do this with the predict function as well)
# augment() created the dataset immediately
sales_fitted <- augment(lm(Sales ~ p1 + p2, data = sales))
# Plot the density function of the residuals (check for normality)
ggplot(data = sales_fitted, aes(x = .std.resid)) +
geom_density(color = "#E16462", lwd = 1.3)+
theme_bw()+
xlab("Std. Residuals") + ylab("Density")
# Plot the residuals against the fitted values to check for homoskedasticity (or heteroskedasticity)
ggplot(data = sales_fitted, aes(x = .fitted, y = .std.resid)) +
geom_point(color = "#E16462", fill = alpha("#E16462",0.4), pch=22, size = 3)+ #scatter plot
geom_smooth(method = "lm", color = "dark grey", se = FALSE, lty = 2, lwd = 1.3) + #fit the regression line
theme_bw()+
xlab("Sales_hat") + ylab("Residuals")
# Plot the observed sales values against the fitted values (see how well we are predicting)
ggplot(data = sales_fitted, aes(x = .fitted, y = Sales)) +
geom_point(color = "#900DA4", fill = alpha("#900DA4",0.4), pch=22, size = 3)+
geom_smooth(method = "lm", color = "dark grey", se = FALSE, lty = 2, lwd = 1.3) +
theme_bw()+
xlab("Sales_hat") + ylab("Sales")
# What if we only had p1 and not p2? How would the plot look?
summary(lm(Sales ~ p1, data = sales))
sales_fitted_p1 <- augment(lm(Sales ~ p1, data = sales))
ggplot(data = sales, aes(x = p1, y = Sales)) +
geom_point(color = "#F89441", fill = alpha("#F89441",0.4), pch=22, size = 3)+
geom_smooth(method = "lm", color = "dark grey", se = FALSE, lty = 2, lwd = 1.3) +
theme_bw()+
xlab("Sales_hat") + ylab("Sales")
### Beer data
beers <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Classes/Week2/1_OLS/data/beer.csv")
head(beers)
# How does the relationship between height and beers look like?
ggplot(data = beers, aes(x = height, y = nbeer)) +
geom_point(color = "#F89441", fill = alpha("#F89441",0.4), pch=22, size = 3)+
geom_smooth(method = "lm", color = "dark grey", se = FALSE, lty = 2, lwd = 1.3) +
theme_bw()+
xlab("height") + ylab("nbeer")
# Let's check out the model
summary(lm(nbeer ~ height, data = beers))
# What happens now if we control for weight?
summary(lm(nbeer ~ weight + height, data = beers))
# We can also regress the residuals from the simple model (sales on weight) on height
# to see what's left there to explain:
beers_fitted_weight <- augment(lm(nbeer ~ weight, data = beers))
beers_fitted_weight$height <- beers$height
ggplot(data = beers_fitted_weight, aes(x = height, y = .std.resid)) +
geom_point(color = "#F89441", fill = alpha("#F89441",0.4), pch=22, size = 3)+
geom_smooth(method = "lm", color = "dark grey", se = FALSE, lty = 2, lwd = 1.3) +
theme_bw()+
xlab("height") + ylab("resid(nbeer|weight)")
# Let's look at the correlation between variables:
M <-cor(beers)
ggcorrplot(M, method = "circle", outline.color = "white", ggtheme = ggplot2::theme_bw)
# You can keep playing with the data! Add female, age, etc.
# For example, add weight and weight^2
summary(lm(nbeer ~ weight + I(weight^2), data = beers))
# Create a new factor variable (it's fake, but it will help to illustrate the point)
set.seed(100) # we set a seed to ensure replication
beers$year = sample(c("freshmen","sophmore","junior","senior"),nrow(beers),replace = TRUE) # generate a random variable of the year the student is in.
table(beers$year)
summary(lm(nbeer ~ weight + factor(year), data = beers)) # Which one is the base category?
####### Binary outcomes
library(AER)
data("HMDA")
# To know what the variables are, you can type ?HMDA on the console
hmda <- data.frame(HMDA)
head(hmda)
#Let's transform the variable deny into a 0-1 variable:
hmda$deny = as.numeric(hmda$deny) - 1
## Linear Probability Model
# Let's run a simple model:
summary(lm(deny ~ pirat, data = hmda))
# Let's look at the fitted regression line and the data:
ggplot(data = hmda, aes(x = pirat, y = deny)) +
geom_point(color = "#5601A4", fill = alpha("#5601A4",0.4), pch=21, size = 3)+
geom_smooth(method = "lm", color = "#BF3984", se = FALSE, lty = 1, lwd = 1.3) +
geom_hline(aes(yintercept = 0), color="dark grey", lty = 2, lwd=1)+
geom_hline(aes(yintercept = 1), color="dark grey", lty = 2, lwd=1)+
theme_bw()+
xlab("Payment/Income ratio") + ylab("Deny")
# Let's run robust standard errors now
library(estimatr)
model2 <- estimatr::lm_robust(deny ~ pirat, data = hmda)
summary(model2)
# We can add more variables too:
model3 <- estimatr::lm_robust(deny ~ pirat + factor(afam), data = hmda)
summary(model3)
## Logistic Regression
logit1 <- glm(deny ~ pirat, family = binomial(link = "logit"),
data = hmda)
prob <- predict(logit1, type = "response") # probabilities
# Let's plot the predicted probabilities using logit and the data that we have!
ggplot(data = hmda, aes(x = pirat, y = deny)) +
geom_point(color = "#5601A4", fill = alpha("#5601A4",0.4), pch=21, size = 3)+ # This is a scatter plot for the data
geom_line(aes(x = pirat, y = prob), color = "#BF3984", lty = 1, lwd = 1.3) + #This are the fitted probabilities
geom_hline(aes(yintercept = 0), color="dark grey", lty = 2, lwd=1)+
geom_hline(aes(yintercept = 1), color="dark grey", lty = 2, lwd=1)+
theme_bw()+
xlab("Payment/Income ratio") + ylab("Deny")
# To interpret coefficients, we need to choose the values for the other variables (in this case,
# the mean for payments to income ratio)
logit2 <- glm(deny ~ pirat + factor(afam), family = binomial(link = "logit"),
data = hmda) # This is the model we are fitting with two covariates
# We need to pass to predict: The model we fitted, the new data we want to fit our probabilities (if we leave blank, it uses the original hmda data)
# and we need to say type = "response" to get *probabilities* (and not odds, or log odds, or anything else)
predictions_afam <- predict(logit2, newdata = data.frame("afam" = c("no", "yes"),
"pirat" = c(mean(hmda$pirat), mean(hmda$pirat))),
type = "response")
# These are the predictions for two observations with the same payment/income ratio (the mean of our data)
# and where one is african american and the other one is not.
predictions_afam
# Difference between both predictions
diff(predictions_afam)
##############################################################
### Title: "Week 6 - Natural Experiments and Diff-in-Diff"
### Course: STA 235
### Semester: Spring 2021
### Professor: Magdalena Bennett
##############################################################
# Clears memory
rm(list = ls())
# Clears console
cat("\014")
### Load libraries
# If you don't have one of these packages installed already, you will need to run install.packages() line
library(tidyverse)
library(ggplot2)
library(generics)
library(estimatr)
library(designmatch)
library(MatchIt)
library(broom)
#####################################################################
## Oregon Insurance Plan example
d <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Classes/Week6/data/oregonhie_simplified.csv") #This might take a while (it's a lot of data!)
head(d)
d <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Classes/Week6/data/oregonhie_simplified.csv", stringsAsFactors = TRUE)
d <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Classes/Week6/data/oregonhie_simplified.csv") #Load the data (almost 75k obs)
table(d$treatment)
table(d$treatment, d$applied_app)
library(vtab)
View(d) #This is also good to look at all your data
library(vtable)
install.packages(vtable)
install.packages("vtable")
library(vtable)
vtable(d)
?mutate_at
d <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Classes/Week6/data/oregonhie_simplified.csv") #Load the data (almost 75k obs)
#First, always inspect the data:
table(d$treatment)
table(d$treatment, d$applied_app)
View(d) #This is also good to look at all your data
d <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Classes/Week6/data/oregonhie_simplified.csv") #Load the data (almost 75k obs)
#First, always inspect the data:
table(d$treatment)
table(d$treatment, d$applied_app)
vtable(d) #This is also good to look at all your data
d_covs <- d %>% dplyr::select(birthyear_list, have_phone_list, english_list, female_list, week_list, zip_msa_list, pobox_list,
any_visit_pre_ed, num_visit_pre_cens_ed, any_hosp_pre_ed, num_hosp_pre_ed, charge_tot_pre_ed)
d_covs <- d %>% dplyr::select(birthyear_list, have_phone_list, english_list, female_list, week_list, zip_msa_list, pobox_list,
any_visit_pre_ed, num_visit_pre_cens_ed, any_hosp_pre_ed, num_hosp_pre_cens_ed, charg_tot_pre_ed)
meantab(d_covs, d$treatment, which(d$treatment==1), which(d$treatment==0))
##############################################################
### Title: "Week 6 - Natural Experiments and Diff-in-Diff"
### Course: STA 235
### Semester: Spring 2021
### Professor: Magdalena Bennett
##############################################################
# Clears memory
rm(list = ls())
# Clears console
cat("\014")
### Load libraries
# If you don't have one of these packages installed already, you will need to run install.packages() line
library(tidyverse)
library(ggplot2)
library(generics)
library(estimatr)
library(designmatch)
library(MatchIt)
library(broom)
library(vtable) #Useful package to visualize data
library(cobalt)
#####################################################################
## Oregon Insurance Plan example
d <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Classes/Week6/data/oregonhie_simplified.csv") #Load the data (almost 75k obs)
#First, always inspect the data:
table(d$treatment)
table(d$treatment, d$applied_app)
vtable(d) #This is also good to look at all your data
d_covs <- d %>% dplyr::select(birthyear_list, have_phone_list, english_list, female_list, week_list, zip_msa_list, pobox_list)
meantab(d_covs, d$treatment, which(d$treatment==1), which(d$treatment==0))
?filter
d_12m <- d %>% dplyr::filter(sample_12m==1)
d_12m <- d %>% dplyr::filter(sample_12m==1)
d_12m_covs <- d_12m %>% dplyr::select(birthyear_list, have_phone_list, english_list, female_list, week_list, zip_msa_list, pobox_list)
meantab(d_12m_covs, d_12m$treatment, which(d_12m$treatment==1), which(d_12m$treatment==0))
table(d_12m$treatment,d_12m$returned_12m)
d_12m %>% group_by(treatment) %>% summarise(mean_response = mean(returned_12m, na.rm = TRUE))
summary(estimatr::lm_robust(returned_12m ~ treatment, data = d_12m))
?glm
m1 <- glm(returned_12m ~ birthyear_list + have_phone_list + english_list + female_list + week_list + zip_msa_list + pobox_list,
data = d_12m, family = binomial(link = "logit"))
?augment
d_12m_aug <- broom::augment(m1, d_12m, type.predict = "response")
d_12m_aug <- broom::augment(m1, d_12m, type.predict = "response")
summary(m1)
table(d_12m$returned_12m)
length(predict(m1, d_12m))
m1 <- glm(returned_12m ~ birthyear_list + have_phone_list + english_list + female_list + week_list + zip_msa_list + pobox_list,
data = d_12m, family = binomial(link = "logit"))
d_12m_aug <- broom::augment(m1, d_12m, type.predict = "response")
rlang::last_error()
rlang::last_trace()
?augment
d_12m_aug <- generics::augment(m1, d_12m, type.predict = "response")
d_12m_aug <- generics::augment(m1, d_12m)
##############################################################
### Title: "Week 6 - Natural Experiments and Diff-in-Diff"
### Course: STA 235
### Semester: Spring 2021
### Professor: Magdalena Bennett
##############################################################
# Clears memory
rm(list = ls())
# Clears console
cat("\014")
### Load libraries
# If you don't have one of these packages installed already, you will need to run install.packages() line
library(tidyverse)
library(ggplot2)
library(generics)
library(estimatr)
library(designmatch)
library(MatchIt)
library(broom)
library(vtable) #Useful package to visualize data
library(cobalt)
#####################################################################
## Oregon Insurance Plan example
d <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Classes/Week6/data/oregonhie_simplified.csv") #Load the data (almost 75k obs)
#First, always inspect the data:
table(d$treatment)
table(d$treatment, d$applied_app)
vtable(d) #This is also good to look at all your data
#Note that variables ending in _list come from one dataset and variables ending in _1m come from another dataset (12 month survey)
## Let's look at the balance
d_covs <- d %>% dplyr::select(birthyear_list, have_phone_list, english_list, female_list, week_list, zip_msa_list, pobox_list)
meantab(d_covs, d$treatment, which(d$treatment==1), which(d$treatment==0))
# Question: Statistically significant differences. What can we do?
## Let's look at a subsample (the ones that were surveyed 12months later)
d_12m <- d %>% dplyr::filter(sample_12m==1)
d_12m_covs <- d_12m %>% dplyr::select(birthyear_list, have_phone_list, english_list, female_list, week_list, zip_msa_list, pobox_list)
meantab(d_12m_covs, d_12m$treatment, which(d_12m$treatment==1), which(d_12m$treatment==0))
## What about survey responses?
table(d_12m$treatment,d_12m$returned_12m) #Look at responses by treatment status
#That was not very clear.. let's use the tidyverse!
d_12m %>% group_by(treatment) %>% summarise(mean_response = mean(returned_12m, na.rm = TRUE))
summary(estimatr::lm_robust(returned_12m ~ treatment, data = d_12m)) #The difference in non-response is significant.
## Let's use weights to approximate response:
m1 <- glm(returned_12m ~ birthyear_list + have_phone_list + english_list + female_list + week_list + zip_msa_list + pobox_list,
data = d_12m, family = binomial(link = "logit"))
d_12m_aug <- broom::augment(m1, d_12m, type.predict = "response")
d_12m_aug <- broom::augment(m1, data = d_12m, type.predict = "response")
d_12m_aug <- broom::augment(m1, data = tibble(d_12m), type.predict = "response")
d_12m <- tibble(d_12m)
View(d_12m)
head(predict(m1,d_12m,type="response"))
d_12m$prob_response <-predict(m1, data = d_12m, type = "response")
x <- predict(m1, data = d_12m, type = "response")
head(x)
prob_response <-predict(m1, data = d_12m, type = "response")
prob_response <-predict(m1, data = d_12m, type = "response")
match_id <- as.numeric(rownames(prob_response))
match_id <- as.numeric(colnames(prob_response))
dim(x)
head(as.numeric(names(prob_response)))
match_id <- as.numeric(names(prob_response))
max(match_id)
d_12m$prob_response <- NA
d_12m$prob_response[match_id] <- prob_response
d_12m <- d_12m %>% mutate(weights = returned_12m/prob_response + (1-returned_12m)/(1-prob_response))
d_12m_aug <- broom::augment(m1, newdata = tibble(d_12m), type.predict = "response")
d_12m_aug <- broom::augment(m1, newdata = d_12m, type.predict = "response")
#Notice that we need to use the "newdata" because we can't estimate all probabilities (there's one observation where we can't predict a probability)
d_12m_aug <- broom::augment(m1, newdata = d_12m, type.predict = "response")
# Create the weights: We want the responders to look more like the whole sample. Which weight should we use?
d_12m_aug <- d_12m_aug %>% mutate(weights = returned_12m/prob_response + (1-returned_12m)/(1-prob_response))
summary(estimatr::lm_robust(ins_any_12m ~ treatment, data = d_12m_aug, weights = weights))
summary(estimatr::lm_robust(needmet_med_cor_12m ~ treatment, data = d_12m_aug, weights = weights))
summary(estimatr::lm_robust(smk_curr_12m ~ treatment, data = d_12m_aug, weights = weights))
pagedown::chrome_print('C:/Users/mc72574/Dropbox/Hugo/Sites/sta235/exampleSite/content/Classes/Week6/1_Natural_Experiments/sp2021_sta235_8_natural_experiments.html')
pagedown::chrome_print('C:/Users/mc72574/Dropbox/Hugo/Sites/sta235/exampleSite/content/Classes/Week6/1_Natural_Experiments/sp2021_sta235_8_natural_experiments.html')
pagedown::chrome_print('C:/Users/mc72574/Dropbox/Hugo/Sites/sta235/exampleSite/content/Classes/Week6/1_Natural_Experiments/sp2021_sta235_8_natural_experiments.html')
?kable
library(scales)
gb_trends <- expand_grid(type = c("Early", "Late"), month = 1:12) %>%
mutate(income = case_when(
type == "Late" & month <= 8 ~ 100 + 75 * month,
type == "Late" & month > 8 ~ 100 + 75 * month + 200,
type == "Early" & month <= 4 ~ 100 + 75 * month + 200,
type == "Early" & month > 4 ~ 100 + 75 * month + 400
)) %>%
mutate(month_f = fct_inorder(factor(month)))
ggplot(gb_trends, aes(x = month, y = income, color = type)) +
geom_smooth(data = filter(gb_trends, type == "Early", month <= 4),
aes(x = month, y = income), inherit.aes = FALSE,
method = "lm", fullrange = TRUE, se = FALSE,
color = "#B10DC9", size = 1, linetype = "22") +
geom_smooth(data = filter(gb_trends, type == "Late", month <= 7),
aes(x = month, y = income), inherit.aes = FALSE,
method = "lm", fullrange = TRUE, se = FALSE,
color = "#001f3f", size = 1, linetype = "22") +
geom_vline(xintercept = c(4.5, 8.5), size = 1) +
geom_line(size = 3) +
scale_color_manual(values = c("#900DA4", "#FCCE25"), name = NULL) +
scale_x_continuous(breaks = 1:12) +
scale_y_continuous(labels = dollar) +
labs(x = "Month", y = "Income") +
theme_bw(base_size = 21, base_family = "Fira Sans Condensed") +
theme(panel.grid.major.x = element_blank())+
theme_ipsum_fsc(plot_title_face = "bold",plot_title_size = 24) +
theme(axis.title.x = element_text(size=18),#margin = margin(t = 10, r = 0, b = 0, l = 0)),
axis.text.x = element_text(size=18),
axis.title.y = element_text(size=18),#margin = margin(t = 0, r = 10, b = 0, l = 0)),
axis.text.y = element_blank(),
legend.title = element_blank(),
legend.text = element_text(size=15),
legend.background = element_rect(fill="white",colour ="white"),
title = element_text(size=14))
library(tidyverse)
library(gganimate)
library(ggthemes)
library(gifski)
library(plotly)
library(leaflet)
library(ggplot2)
library(firasans)
library(hrbrthemes)
library(extrafont)
library("RColorBrewer")
library(viridis)
library("tm")
library("SnowballC")
library("wordcloud")
library("RColorBrewer")
library("firasans")
library(hrbrthemes)
library(extrafont)
library(kableExtra)
library(scales)
ggplot(gb_trends, aes(x = month, y = income, color = type)) +
geom_smooth(data = filter(gb_trends, type == "Early", month <= 4),
aes(x = month, y = income), inherit.aes = FALSE,
method = "lm", fullrange = TRUE, se = FALSE,
color = "#B10DC9", size = 1, linetype = "22") +
geom_smooth(data = filter(gb_trends, type == "Late", month <= 7),
aes(x = month, y = income), inherit.aes = FALSE,
method = "lm", fullrange = TRUE, se = FALSE,
color = "#001f3f", size = 1, linetype = "22") +
geom_vline(xintercept = c(4.5, 8.5), size = 1) +
geom_line(size = 3) +
scale_color_manual(values = c("#900DA4", "#FCCE25"), name = NULL) +
scale_x_continuous(breaks = 1:12) +
scale_y_continuous(labels = dollar) +
labs(x = "Month", y = "Income") +
theme_bw(base_size = 21, base_family = "Fira Sans Condensed") +
theme(panel.grid.major.x = element_blank())+
theme_ipsum_fsc(plot_title_face = "bold",plot_title_size = 24) +
theme(axis.title.x = element_text(size=18),#margin = margin(t = 10, r = 0, b = 0, l = 0)),
axis.text.x = element_text(size=18),
axis.title.y = element_text(size=18),#margin = margin(t = 0, r = 10, b = 0, l = 0)),
axis.text.y = element_blank(),
legend.title = element_blank(),
legend.text = element_text(size=15),
legend.background = element_rect(fill="white",colour ="white"),
title = element_text(size=14))
plot_early <- ggplot(gb_trends, aes(x = month, y = income, color = type)) +
geom_ribbon(data = filter(gb_trends, type == "Early", month <= 6),
aes(x = month, ymin = -Inf, ymax = Inf, color = NULL),
fill = "grey20", alpha = 0.2) +
geom_smooth(data = filter(gb_trends, type == "Early", month <= 4),
aes(x = month, y = income), inherit.aes = FALSE,
method = "lm", fullrange = TRUE, se = FALSE,
color = "#B10DC9", size = 1, linetype = "22") +
geom_smooth(data = filter(gb_trends, type == "Late", month <= 7),
aes(x = month, y = income), inherit.aes = FALSE,
method = "lm", fullrange = TRUE, se = FALSE,
color = "#001f3f", size = 1, linetype = "22") +
geom_vline(xintercept = c(4.5, 8.5), size = 1) +
geom_line(size = 3) +
scale_color_manual(values = c("#900DA4", "#FCCE25"), name = NULL) +
scale_x_continuous(breaks = 1:12) +
scale_y_continuous(labels = dollar) +
labs(x = "Month", y = "Income",
subtitle = "Positive effect for early group") +
guides(color = FALSE) +
theme_bw(base_size = 21, base_family = "Fira Sans Condensed") +
theme(panel.grid.major.x = element_blank())+
theme(axis.title.x = element_text(size=18),#margin = margin(t = 10, r = 0, b = 0, l = 0)),
axis.text.x = element_text(size=18),
axis.title.y = element_text(size=18),#margin = margin(t = 0, r = 10, b = 0, l = 0)),
axis.text.y = element_blank(),
legend.title = element_blank(),
legend.text = element_text(size=15),
legend.background = element_rect(fill="white",colour ="white"),
title = element_text(size=14))
plot_early
plot_late <- ggplot(gb_trends, aes(x = month, y = income, color = type)) +
geom_ribbon(data = filter(gb_trends, type == "Early", month >= 7),
aes(x = month, ymin = -Inf, ymax = Inf, color = NULL),
fill = "grey20", alpha = 0.2) +
geom_smooth(data = filter(gb_trends, type == "Early", month <= 4),
aes(x = month, y = income), inherit.aes = FALSE,
method = "lm", fullrange = TRUE, se = FALSE,
color = "#B10DC9", size = 1, linetype = "22") +
geom_smooth(data = filter(gb_trends, type == "Late", month <= 7),
aes(x = month, y = income), inherit.aes = FALSE,
method = "lm", fullrange = TRUE, se = FALSE,
color = "#001f3f", size = 1, linetype = "22") +
geom_vline(xintercept = c(4.5, 8.5), size = 1) +
geom_line(size = 3) +
scale_color_manual(values = c("#900DA4", "#FCCE25"), name = NULL) +
scale_x_continuous(breaks = 1:12) +
scale_y_continuous(labels = dollar) +
labs(x = "Month", y = NULL,
subtitle = "Negative effect for early group!") +
theme_bw(base_size = 21, base_family = "Fira Sans Condensed") +
theme(panel.grid.major.x = element_blank())+
theme_ipsum_fsc(plot_title_face = "bold",plot_title_size = 24) +
theme(axis.title.x = element_text(size=18),#margin = margin(t = 10, r = 0, b = 0, l = 0)),
axis.text.x = element_text(size=18),
axis.title.y = element_text(size=18),#margin = margin(t = 0, r = 10, b = 0, l = 0)),
axis.text.y = element_blank(),
legend.title = element_blank(),
legend.text = element_text(size=15),
legend.background = element_rect(fill="white",colour ="white"),
title = element_text(size=14))
plot_late
plot_early + plot_late
library(patchwork)
install.packages("bacondecomp")
d <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Classes/Week6/data/taylorswift.csv")
d <- read.csv("https://raw.githubusercontent.com/maibennett/sta235/main/exampleSite/content/Classes/Week6/data/taylorswift.csv")
head(d)
